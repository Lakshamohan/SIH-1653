# Smart India Hackathon Workshop
# Date:08.03.2025
## Register Number:212224220050
## Name: LAKSHA M
## Problem Title
SIH 1653: Web based Selector-Applicant Simulation Software
## Problem Description
Background: Recruitment and Assessment Centre (RAC) under DRDO, Ministry of Defence carries out interviews for applications received against advertised vacancies and for promotion to next higher grade for scientific manpower inducted within DRDO. Description: The process of interviewing is a challenging task. An unbiased objective interviewing process helps identify the right talent. The basic process of an interview involves posing a set of questions by an interviewer and thereafter evaluating responses from candidates. Thus, the questions asked should be relevant and match the area/ expertise of the applicant and the responses should also be of relevance w.r.t. the question asked. Expected Solution: The proposed solution should provide experts as well as candidates a real life Board Room experience, starting with initial ice-breaking questions leading to in-depth techno-managerial (depending on the level of candidate) questions. It shall also be able to provide a quantifiable score for experts as well as the candidate for the relevancy of questions w.r.t. the area/ expertise of the applicant. Similarly, candidate responses should also be graded for relevancy w.r.t. the question asked, finally assisting in arriving at an overall score for the subject knowledge of the candidate and thus his/ her suitability against the advertised post.

## Problem Creater's Organization
Ministry of Defence

## Idea
This problem requires developing a Web-based Selector-Applicant Simulation Software that replicates a real-life Board Room Interview experience. The system should facilitate structured interviews, ensuring relevance, fairness, and quantifiable evaluation of candidates.

Key Functionalities to Implement
Simulated Board Room Experience

Interactive UI for experts (interviewers) and candidates.
Initial ice-breaking questions followed by in-depth technical/managerial questions.
Automated Question Relevance Matching

System should dynamically suggest relevant questions based on the applicant’s area of expertise.
Categorization of questions based on difficulty level, technical/managerial aspects.
Candidate Response Evaluation

AI/NLP-based grading system to assess candidate responses for relevance and accuracy.
Provide quantifiable scores for candidate responses.
Expert Performance Evaluation

Evaluate the relevance of questions asked by experts.
Score experts based on their questioning effectiveness.
Final Candidate Suitability Score

A weighted scoring system to determine overall subject knowledge and fit for the advertised post.


## Proposed Solution / Architecture Diagram
![Screenshot 2025-03-08 112948](https://github.com/user-attachments/assets/0c861144-2219-41da-b7d8-64c4278e5e07)



## Use Cases
![Screenshot 2025-03-08 113054](https://github.com/user-attachments/assets/ec36e032-b204-4f30-aad9-665b5dee4e1d)


## Technology Stack
Frontend: React.js / Angular.js (for interactive UI)
Backend: Node.js / Django / Flask (handling business logic)
Database: PostgreSQL / MongoDB (storing questions, responses, scores)
AI/NLP: GPT-based models / BERT (for response evaluation)
Deployment: AWS / Azure / On-premise (for scalability & security)

## Dependencies
Mapping service- 14 days Data collection- 15 days budget- rs.60,000
